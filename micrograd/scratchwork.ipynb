{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "import time\n",
    "\n",
    "from engine import Value\n",
    "from modules import *\n",
    "from ops import *\n",
    "from gpt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "with open('../input.txt', 'r', encoding='utf-8') as f:\n",
    "    tinyShakespeare_string = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d', 'm', 'O', 'h', 'l', 'o', 'S', 'C', 'w', 'V', 'k', 'B', 't', '?', '3', 'v', 'A', 'Q', 'X', 'D', 'x', 'E', 'P', 'T', \"'\", '!', 'i', 'q', 'G', '$', 'R', 'U', 'F', 'Z', ',', ';', 'M', 'p', 'u', 'N', ':', 'L', 'I', 'g', '.', '-', 'f', '&', 's', 'n', 'j', 'r', 'e', 'H', 'K', 'J', 'Y', '\\n', ' ', 'z', 'c', 'y', 'a', 'W', 'b'}\n",
      "{'d': 0, 'm': 1, 'O': 2, 'h': 3, 'l': 4, 'o': 5, 'S': 6, 'C': 7, 'w': 8, 'V': 9, 'k': 10, 'B': 11, 't': 12, '?': 13, '3': 14, 'v': 15, 'A': 16, 'Q': 17, 'X': 18, 'D': 19, 'x': 20, 'E': 21, 'P': 22, 'T': 23, \"'\": 24, '!': 25, 'i': 26, 'q': 27, 'G': 28, '$': 29, 'R': 30, 'U': 31, 'F': 32, 'Z': 33, ',': 34, ';': 35, 'M': 36, 'p': 37, 'u': 38, 'N': 39, ':': 40, 'L': 41, 'I': 42, 'g': 43, '.': 44, '-': 45, 'f': 46, '&': 47, 's': 48, 'n': 49, 'j': 50, 'r': 51, 'e': 52, 'H': 53, 'K': 54, 'J': 55, 'Y': 56, '\\n': 57, ' ': 58, 'z': 59, 'c': 60, 'y': 61, 'a': 62, 'W': 63, 'b': 64}\n",
      "{0: 'd', 1: 'm', 2: 'O', 3: 'h', 4: 'l', 5: 'o', 6: 'S', 7: 'C', 8: 'w', 9: 'V', 10: 'k', 11: 'B', 12: 't', 13: '?', 14: '3', 15: 'v', 16: 'A', 17: 'Q', 18: 'X', 19: 'D', 20: 'x', 21: 'E', 22: 'P', 23: 'T', 24: \"'\", 25: '!', 26: 'i', 27: 'q', 28: 'G', 29: '$', 30: 'R', 31: 'U', 32: 'F', 33: 'Z', 34: ',', 35: ';', 36: 'M', 37: 'p', 38: 'u', 39: 'N', 40: ':', 41: 'L', 42: 'I', 43: 'g', 44: '.', 45: '-', 46: 'f', 47: '&', 48: 's', 49: 'n', 50: 'j', 51: 'r', 52: 'e', 53: 'H', 54: 'K', 55: 'J', 56: 'Y', 57: '\\n', 58: ' ', 59: 'z', 60: 'c', 61: 'y', 62: 'a', 63: 'W', 64: 'b'}\n"
     ]
    }
   ],
   "source": [
    "# Convert the string to bytes\n",
    "unique_chars = set(tinyShakespeare_string)\n",
    "print(unique_chars)\n",
    "v = len(unique_chars)\n",
    "encode_dict, decode_dict = {}, {}\n",
    "for i, c in enumerate(unique_chars):\n",
    "    encode_dict[c] = i\n",
    "    decode_dict[i] = c\n",
    "print(encode_dict)\n",
    "print(decode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "[32, 26, 51, 48, 12, 58, 7, 26, 12, 26, 59, 52, 49, 40, 57, 11, 52, 46, 5, 51, 52, 58, 8, 52, 58, 37, 51, 5, 60, 52, 52, 0, 58, 62, 49, 61, 58, 46, 38, 51, 12, 3, 52, 51, 34, 58, 3, 52, 62, 51, 58, 1, 52, 58, 48, 37, 52, 62, 10, 44, 57, 57, 16, 4, 4, 40, 57, 6, 37, 52, 62, 10, 34, 58, 48, 37, 52, 62, 10, 44, 57, 57, 32, 26, 51, 48, 12, 58, 7, 26, 12, 26, 59, 52, 49, 40, 57, 56, 5, 38]\n"
     ]
    }
   ],
   "source": [
    "tinyShakespeare_chars = [encode_dict[c] for c in tinyShakespeare_string]\n",
    "print(tinyShakespeare_string[:100])\n",
    "print(tinyShakespeare_chars[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 10] [2, 10]\n",
      "[\n",
      "  [32, 26, 51, 48, 12, 58, 7, 26, 12, 26]\n",
      "  [59, 52, 49, 40, 57, 11, 52, 46, 5, 51]\n",
      "]\n",
      "[\n",
      "  [26, 51, 48, 12, 58, 7, 26, 12, 26, 59]\n",
      "  [52, 49, 40, 57, 11, 52, 46, 5, 51, 52]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "split_size = int(0.95 * len(tinyShakespeare_chars))\n",
    "train_dataset, val_dataset = tinyShakespeare_chars[:split_size], tinyShakespeare_chars[split_size:]\n",
    "train_pointer, val_pointer = 0, 0\n",
    "def get_batch(batch_size, seq_len, val = False):\n",
    "    global train_pointer, val_pointer\n",
    "    tok_ct = batch_size * seq_len\n",
    "    dataset = val_dataset if val else train_dataset\n",
    "    pointer = val_pointer if val else train_pointer\n",
    "    input_toks = dataset[pointer:pointer + tok_ct] # grabbing sequential data is bad practice but whatever\n",
    "    target_toks = dataset[pointer + 1:pointer + tok_ct + 1]\n",
    "    if val:\n",
    "        val_pointer += tok_ct\n",
    "    else:\n",
    "        train_pointer += tok_ct\n",
    "    input_toks = split_dim(input_toks, (batch_size, seq_len))\n",
    "    target_toks = split_dim(target_toks, (batch_size, seq_len))\n",
    "    return input_toks, target_toks\n",
    "input_toks, target_toks = get_batch(2, 10)\n",
    "print(get_shape(input_toks), get_shape(target_toks))\n",
    "pretty_tensor_print(input_toks)\n",
    "pretty_tensor_print(target_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 50 20\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'vocab_len':v,\n",
    "    'model_dim':4,\n",
    "    'max_seq_len':20,\n",
    "    'num_heads':2,\n",
    "    'head_dim':2,\n",
    "    'mlp_mult':2,\n",
    "    'dropout_rate':0.1,\n",
    "    'num_layers':1\n",
    "}\n",
    "model = GPT(config)\n",
    "\n",
    "eta = 0.01\n",
    "\n",
    "batch_size = 8\n",
    "toks_per_batch = batch_size * config['max_seq_len']\n",
    "train_iterations = min(split_size // toks_per_batch, 1000)\n",
    "val_iterations = min((len(tinyShakespeare_chars) - split_size) // toks_per_batch, 50)\n",
    "val_frequency = train_iterations // val_iterations\n",
    "print(train_iterations, val_iterations, val_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King RiLhNhoNNhhh\n"
     ]
    }
   ],
   "source": [
    "def greedy_inference(model, input, gen_len):\n",
    "    gen_len = min(gen_len, config['max_seq_len'] - len(input) - 1)\n",
    "    toks = [[encode_dict[c] for c in input]]\n",
    "    for i in range(gen_len):\n",
    "        probabilities, _ = model(toks)\n",
    "        argmax = float('-inf')\n",
    "        argmax_idx = None\n",
    "        for i, val in enumerate(probabilities[0][-1]):\n",
    "            if val.data > argmax:\n",
    "                argmax_idx = i\n",
    "                argmax = val.data\n",
    "        toks[0].append(argmax_idx)\n",
    "    return \"\".join(decode_dict[t] for t in toks[0])\n",
    "print(greedy_inference(model, \"King Ri\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 (0.0%) | train loss: 667.90 | val loss: 667.90 | time: 5sec | example: King RiLhNhoNNhhh\n",
      "step 20 (0.0%) | train loss: 545.34 | val loss: 553.74 | time: 100sec | example: King Ri          \n",
      "step 40 (0.0%) | train loss: 535.66 | val loss: 516.84 | time: 199sec | example: King Ri          \n",
      "step 60 (0.1%) | train loss: 529.96 | val loss: 527.38 | time: 297sec | example: King Ri          \n",
      "step 80 (0.1%) | train loss: 555.99 | val loss: 546.65 | time: 397sec | example: King Ri          \n",
      "step 100 (0.1%) | train loss: 514.19 | val loss: 516.15 | time: 511sec | example: King Ri          \n",
      "step 120 (0.1%) | train loss: 524.04 | val loss: 599.85 | time: 609sec | example: King Ri          \n",
      "step 140 (0.1%) | train loss: 495.97 | val loss: 545.58 | time: 709sec | example: King Ri          \n",
      "step 160 (0.2%) | train loss: 515.41 | val loss: 578.22 | time: 885sec | example: King Ri          \n",
      "step 180 (0.2%) | train loss: 559.99 | val loss: 571.34 | time: 996sec | example: King Ri          \n"
     ]
    }
   ],
   "source": [
    "pointer = 0\n",
    "start_time = time.time()\n",
    "for i in range(train_iterations):\n",
    "    # forward pass\n",
    "    train_input_toks, train_target_toks = get_batch(batch_size, config['max_seq_len'])\n",
    "    probabilities, train_loss = model(train_input_toks, train_target_toks)\n",
    "        \n",
    "    if i % val_frequency == 0:\n",
    "        val_input_toks, val_target_toks = get_batch(batch_size, config['max_seq_len'], val = True)\n",
    "        probabilities, val_loss = model(val_input_toks, val_target_toks)\n",
    "        \n",
    "        print(f'step {i} ({(i / train_iterations):.1f}%) | train loss: {train_loss.data:.2f} | val loss: {val_loss.data:.2f} | ' \n",
    "              f'time: {int(time.time() - start_time)}sec | example: {greedy_inference(model, \"King Ri\", 10)}')\n",
    "\n",
    "    ## backward pass\n",
    "    #set param gradients to 0\n",
    "    for p in model.parameters():\n",
    "        p.grad = 0.0\n",
    "    # clac gradients\n",
    "    train_loss.backward()\n",
    "    # performing a step of SGD\n",
    "    for p in model.parameters():\n",
    "        p.data -= eta * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'King Ri t t t e t'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_inference(model, \"King Ri\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
