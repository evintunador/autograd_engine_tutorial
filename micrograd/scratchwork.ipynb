{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "\n",
    "from engine import Value\n",
    "from modules import *\n",
    "from ops import *\n",
    "from gpt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "vocab_len = 10\n",
    "model_dim = 8\n",
    "max_seq_len = 5\n",
    "seq_len = 3\n",
    "num_heads = 2\n",
    "head_dim = 4\n",
    "mlp_mult = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(Module):\n",
    "    def __init__(self, vocab_len: int, pad_token: int = None):\n",
    "        self.vocab_len = vocab_len\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    def __call__(self, logits, targets):\n",
    "        '''\n",
    "        inputs: \n",
    "        logits - list of lists of lists of shape (batch_size, seq_len, vocab_len) full of Value objects\n",
    "        targets - list of lists of shape (batch_size, seq_len) full of integers representing token indices\n",
    "\n",
    "        output: a single Value object representing loss of the model\n",
    "        '''\n",
    "        assert isinstance(targets, list) and isinstance(targets[0], list) and isinstance(targets[0][0], int)\n",
    "        assert len(logits) == len(targets) and len(logits[0]) == len(targets[0])\n",
    "        # prolly should assert that each vec in logits is a valid distribution (sums to 1)\n",
    "                                                  \n",
    "        one_hots = vector_wise_apply(self._one_hot, targets)\n",
    "        pretty_print_tensor(one_hots)\n",
    "\n",
    "        log_logits = vector_wise_apply(log, logits)\n",
    "        pretty_print_tensor(log_logits)\n",
    "\n",
    "        losses = entry_wise_mult(one_hots, log_logits)\n",
    "        pretty_print_tensor(losses)\n",
    "\n",
    "        # sum\n",
    "\n",
    "        # mult by -1\n",
    "\n",
    "        # return\n",
    "        \n",
    "\n",
    "    def _one_hot(self, targets_vec):\n",
    "        '''\n",
    "        turns list of tokens into list of one-hot vectors with 1's at the index of the given token\n",
    "        meant to be used with vector_wise_apply\n",
    "        '''\n",
    "        assert all(isinstance(t, int) for t in targets_vec)\n",
    "        return [[0] * t + [1] + [0] * (vocab_len - t - 1) for t in targets_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum(vec):\n",
    "    '''\n",
    "    sums up all values in a vector\n",
    "    returns a single Value object, so if it's being called by vector_wise_apply that means it removes the last dimension in the process\n",
    "    '''\n",
    "    assert isinstance(vec, list) and isinstance(vec[0], (float, int, Value))\n",
    "    tot = vec[0]\n",
    "    for x in vec[1:]:\n",
    "        tot = tot + x\n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 8]\n",
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "x = [[[Value(r.uniform(-1,1)).exp() for _ in range(model_dim)]\n",
    "      for _ in range(seq_len)]\n",
    "     for _ in range(batch_size)]\n",
    "print(get_shape(x))\n",
    "y = vector_wise_apply(sum, x)\n",
    "print(get_shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    [Value(data=1.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000)]\n",
      "    [Value(data=0.000, grad=0.000), Value(data=1.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000)]\n",
      "    [Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=1.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000)]\n",
      "  ]\n",
      "  [\n",
      "    [Value(data=0.000, grad=0.000), Value(data=0.995, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.005, grad=0.000), Value(data=0.000, grad=0.000)]\n",
      "    [Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=1.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000)]\n",
      "    [Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=1.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000), Value(data=0.000, grad=0.000)]\n",
      "  ]\n",
      "]\n",
      "[\n",
      "  [8, 9, 5]\n",
      "  [0, 0, 2]\n",
      "]\n",
      "[\n",
      "  [\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "  ]\n",
      "  [\n",
      "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "  ]\n",
      "]\n",
      "[\n",
      "  [\n",
      "    [Value(data=-0.000, grad=0.000), Value(data=-27.968, grad=0.000), Value(data=-28.205, grad=0.000), Value(data=-21.323, grad=0.000), Value(data=-28.177, grad=0.000), Value(data=-28.223, grad=0.000), Value(data=-28.112, grad=0.000), Value(data=-22.800, grad=0.000), Value(data=-25.862, grad=0.000), Value(data=-28.095, grad=0.000)]\n",
      "    [Value(data=-22.110, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-18.535, grad=0.000), Value(data=-26.370, grad=0.000), Value(data=-23.268, grad=0.000), Value(data=-25.788, grad=0.000), Value(data=-26.350, grad=0.000), Value(data=-26.323, grad=0.000), Value(data=-10.964, grad=0.000), Value(data=-26.301, grad=0.000)]\n",
      "    [Value(data=-40.292, grad=0.000), Value(data=-39.658, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-40.660, grad=0.000), Value(data=-37.004, grad=0.000), Value(data=-40.585, grad=0.000), Value(data=-40.649, grad=0.000), Value(data=-25.432, grad=0.000), Value(data=-33.972, grad=0.000), Value(data=-40.608, grad=0.000)]\n",
      "  ]\n",
      "  [\n",
      "    [Value(data=-31.883, grad=0.000), Value(data=-0.005, grad=0.000), Value(data=-20.830, grad=0.000), Value(data=-41.324, grad=0.000), Value(data=-39.908, grad=0.000), Value(data=-41.445, grad=0.000), Value(data=-24.730, grad=0.000), Value(data=-32.339, grad=0.000), Value(data=-5.206, grad=0.000), Value(data=-40.746, grad=0.000)]\n",
      "    [Value(data=-29.958, grad=0.000), Value(data=-32.924, grad=0.000), Value(data=-19.190, grad=0.000), Value(data=-32.888, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-32.927, grad=0.000), Value(data=-27.668, grad=0.000), Value(data=-17.006, grad=0.000), Value(data=-32.851, grad=0.000), Value(data=-32.911, grad=0.000)]\n",
      "    [Value(data=-12.836, grad=0.000), Value(data=-14.628, grad=0.000), Value(data=-14.646, grad=0.000), Value(data=-14.635, grad=0.000), Value(data=-14.655, grad=0.000), Value(data=-14.560, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-7.770, grad=0.000), Value(data=-14.692, grad=0.000), Value(data=-12.333, grad=0.000)]\n",
      "  ]\n",
      "]\n",
      "[\n",
      "  [\n",
      "    [Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-25.862, grad=0.000), Value(data=-0.000, grad=0.000)]\n",
      "    [Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-26.301, grad=0.000)]\n",
      "    [Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-40.585, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000)]\n",
      "  ]\n",
      "  [\n",
      "    [Value(data=-31.883, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000)]\n",
      "    [Value(data=-29.958, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000)]\n",
      "    [Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-14.646, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000), Value(data=-0.000, grad=0.000)]\n",
      "  ]\n",
      "]\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "logits = [[[Value(r.uniform(-4,4)).exp() for _ in range(vocab_len)]\n",
    "      for _ in range(seq_len)]\n",
    "     for _ in range(batch_size)]\n",
    "logits = vector_wise_apply(softmax, logits)\n",
    "pretty_print_tensor(logits)\n",
    "celoss = CrossEntropyLoss(vocab_len, pad_token = vocab_len - 1)\n",
    "targets = [[r.randint(0, vocab_len - 1) for _ in range(seq_len)]\n",
    "           for _ in range(batch_size)]\n",
    "pretty_print_tensor(targets)\n",
    "loss = celoss(logits, targets)\n",
    "print(loss)\n",
    "pretty_print_tensor(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make Embedding module also do unembedding w/ shared weights? \n",
    "# wouldn't be exactly faithful to pytorch implementation but i'd like to use gradient accumulation & save parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
