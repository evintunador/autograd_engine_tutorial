{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "\n",
    "from engine import Value\n",
    "from modules import *\n",
    "from ops import *\n",
    "from gpt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "vocab_len = 10\n",
    "model_dim = 4\n",
    "seq_len = 5\n",
    "num_heads = 2\n",
    "head_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Module):\n",
    "    def __init__(self, model_dim, num_heads, head_dim, max_seq_len):\n",
    "        self.Wq = Linear(model_dim, num_heads * head_dim)\n",
    "        self.Wk = Linear(model_dim, num_heads * head_dim)\n",
    "        self.Wv = Linear(model_dim, num_heads * head_dim)\n",
    "\n",
    "        # TODO:\n",
    "        # - causal mask\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        assert isinstance(x, list) and isinstance(x[0], list) and isinstance(x[0][0], list) and isinstance(x[0][0][0], Value),\\\n",
    "            \"input to MHSA mechanism must be tensor of ndim==3 for (batch_size, seq_len, model_dim)\"\n",
    "        batch_size, seq_len, model_dim = len(x), len(x[0]), len(x[0][0])\n",
    "        assert self.model_dim == model_dim,\\\n",
    "            f\"input final dimension {model_dim} must equal MHSA mechanism's given model_dim value at initialization of {self.model_dim}\"\n",
    "\n",
    "        q = vector_wise_apply(self.Wq, x) # shape (batch_size, seq_len, num_heads * head_dim)\n",
    "        k = vector_wise_apply(self.Wk, x)\n",
    "        v = vector_wise_apply(self.Wv, x)\n",
    "        # oops i need a split_dim function to separate out num_heads from head_dim\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dim(x, dims):\n",
    "    '''\n",
    "    splits input vector of shape (dims[0] + dims[1]) into matrix of shape (dims[0], dims[1])\n",
    "    '''\n",
    "    assert isinstance(x, list), \"x should be a list of Value objects\"\n",
    "    assert all(isinstance(idx, Value) for idx in x), \"All elements in x must be Value objects\"\n",
    "    # oops i need a vector_wise_apply() function that takes in extra arguments in order to make this work\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_wise_apply(function, vec, extra_arg = None):\n",
    "    '''\n",
    "    applies the input function to the tensor vector-wise\n",
    "    \n",
    "    inputs: \n",
    "        function - a function meant to be applied to a list of Value objects\n",
    "        x - list of lists of .... of Value objects\n",
    "        extra_arg - a second value the function of interest may or may not require as an argument\n",
    "            *i should probably be using **args or **kwargs there somehow but idk how to use those tbh\n",
    "    output: \n",
    "        out - list of lists of .... of Value objects\n",
    "    '''\n",
    "    assert isinstance(x, list), \"input must be at least a vector (aka a list of Value objects)\"\n",
    "    if isinstance(x[0], list):\n",
    "        if extra_arg is not None:\n",
    "            return [vector_wise_apply(function, sub_x, extra_arg) for sub_x in x]\n",
    "        else:\n",
    "            return [vector_wise_apply(function, sub_x) for sub_x in x]\n",
    "    else: # base case: the final vector dimension\n",
    "        return function(x, extra_arg) if extra_arg is not None else function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul(x, c):\n",
    "    '''\n",
    "    multiplies all elements in the vector x by the constant c\n",
    "    for division just input a fraction\n",
    "    '''\n",
    "    assert isinstance(x, list), \"x should be a list of Value objects\"\n",
    "    assert all(isinstance(idx, Value) for idx in x), \"All elements in x must be Value objects\"\n",
    "    return [xi * c for xi in x]\n",
    "\n",
    "def add(x, c):\n",
    "    '''\n",
    "    adds all elements in the vector x by the constant c\n",
    "    for subtraction just input a negative number\n",
    "    '''\n",
    "    assert isinstance(x, list), \"x should be a list of Value objects\"\n",
    "    assert all(isinstance(idx, Value) for idx in x), \"All elements in x must be Value objects\"\n",
    "    return [xi + c for xi in x]\n",
    "\n",
    "# ok so these aren't working cleanly with vector_wise_apply bc it only exxpects 1 input. \n",
    "    # can I somehow use **args or **kwargs? should learn those at some point\n",
    "    # oh yeah i'm gonna need entry-wise mult by a single float for scaling in the attention mechanism\n",
    "    # and i'm gonna need a vector_wise_apply that takes in an extra argument for splitting up num_heads from head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------- test entry-wise add by a single float on a vector -------------\n",
      "[Value(data=-0.172, grad=0.000), Value(data=-0.711, grad=0.000), Value(data=-0.067, grad=0.000), Value(data=-0.150, grad=0.000)]\n",
      "[Value(data=99.828, grad=0.000), Value(data=99.289, grad=0.000), Value(data=99.933, grad=0.000), Value(data=99.850, grad=0.000)]\n",
      "\n",
      "\n",
      "-------------- test entry-wise add by a single float on a tensor -------------\n",
      "[\n",
      "  [\n",
      "    [Value(data=-0.363, grad=0.000), Value(data=-0.318, grad=0.000), Value(data=-0.645, grad=0.000), Value(data=0.022, grad=0.000)]\n",
      "    [Value(data=-0.004, grad=0.000), Value(data=0.639, grad=0.000), Value(data=-0.226, grad=0.000), Value(data=0.417, grad=0.000)]\n",
      "    [Value(data=0.587, grad=0.000), Value(data=-0.842, grad=0.000), Value(data=0.026, grad=0.000), Value(data=-0.295, grad=0.000)]\n",
      "    [Value(data=-0.013, grad=0.000), Value(data=0.628, grad=0.000), Value(data=0.616, grad=0.000), Value(data=0.997, grad=0.000)]\n",
      "    [Value(data=-0.390, grad=0.000), Value(data=0.600, grad=0.000), Value(data=0.457, grad=0.000), Value(data=-0.648, grad=0.000)]\n",
      "  ]\n",
      "  [\n",
      "    [Value(data=0.686, grad=0.000), Value(data=0.120, grad=0.000), Value(data=-0.190, grad=0.000), Value(data=0.566, grad=0.000)]\n",
      "    [Value(data=-0.485, grad=0.000), Value(data=-0.620, grad=0.000), Value(data=0.839, grad=0.000), Value(data=-0.022, grad=0.000)]\n",
      "    [Value(data=-0.068, grad=0.000), Value(data=-0.780, grad=0.000), Value(data=0.977, grad=0.000), Value(data=-0.329, grad=0.000)]\n",
      "    [Value(data=-0.002, grad=0.000), Value(data=-0.475, grad=0.000), Value(data=0.041, grad=0.000), Value(data=-0.387, grad=0.000)]\n",
      "    [Value(data=0.347, grad=0.000), Value(data=0.241, grad=0.000), Value(data=0.977, grad=0.000), Value(data=-0.797, grad=0.000)]\n",
      "  ]\n",
      "]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m pretty_print_tensor(x)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m y \u001b[38;5;241m=\u001b[39m vector_wise_apply(add, x, \u001b[38;5;241m100.\u001b[39m)\n\u001b[1;32m     14\u001b[0m pretty_print_tensor(y)\n",
      "Cell \u001b[0;32mIn[35], line 16\u001b[0m, in \u001b[0;36mvector_wise_apply\u001b[0;34m(function, vec, extra_arg)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [vector_wise_apply(function, sub_x, extra_arg) \u001b[38;5;28;01mfor\u001b[39;00m sub_x \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [vector_wise_apply(function, sub_x) \u001b[38;5;28;01mfor\u001b[39;00m sub_x \u001b[38;5;129;01min\u001b[39;00m x]\n",
      "Cell \u001b[0;32mIn[35], line 16\u001b[0m, in \u001b[0;36mvector_wise_apply\u001b[0;34m(function, vec, extra_arg)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [vector_wise_apply(function, sub_x, extra_arg) \u001b[38;5;28;01mfor\u001b[39;00m sub_x \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [vector_wise_apply(function, sub_x) \u001b[38;5;28;01mfor\u001b[39;00m sub_x \u001b[38;5;129;01min\u001b[39;00m x]\n",
      "    \u001b[0;31m[... skipping similar frames: vector_wise_apply at line 16 (2975 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[35], line 16\u001b[0m, in \u001b[0;36mvector_wise_apply\u001b[0;34m(function, vec, extra_arg)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [vector_wise_apply(function, sub_x, extra_arg) \u001b[38;5;28;01mfor\u001b[39;00m sub_x \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [vector_wise_apply(function, sub_x) \u001b[38;5;28;01mfor\u001b[39;00m sub_x \u001b[38;5;129;01min\u001b[39;00m x]\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('\\n\\n-------------- test entry-wise add by a single float on a vector -------------')\n",
    "x = [Value(r.uniform(-1,1)) for _ in range(model_dim)]\n",
    "print(x)\n",
    "y = add(x, 100.)\n",
    "print(y)\n",
    "# tensor\n",
    "print('\\n\\n-------------- test entry-wise add by a single float on a tensor -------------')\n",
    "x = [[[Value(r.uniform(-1,1)) for _ in range(model_dim)]\n",
    "      for _ in range(seq_len)]\n",
    "     for _ in range(batch_size)]\n",
    "pretty_print_tensor(x)\n",
    "print('\\n')\n",
    "y = vector_wise_apply(add, x, 100.)\n",
    "pretty_print_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
