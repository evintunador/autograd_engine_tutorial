{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "\n",
    "from engine import Value\n",
    "from modules import *\n",
    "from ops import *\n",
    "from gpt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "vocab_len = 10\n",
    "model_dim = 8\n",
    "max_seq_len = 5\n",
    "seq_len = 3\n",
    "num_heads = 2\n",
    "head_dim = 4\n",
    "mlp_mult = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(Module):\n",
    "    def __init__(self, pad_token):\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    def __call__(self, logits, targets):\n",
    "        '''\n",
    "        inputs: \n",
    "        logits - list of lists of lists of shape (batch_size, seq_len, vocab_len) full of Value objects\n",
    "        targets - list of lists of shape (batch_size, seq_len) full of integers representing token indices\n",
    "\n",
    "        output: a single Value object representing loss of the model\n",
    "        '''\n",
    "        # idk how i went straight to this without doing Log first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=2.718, grad=0.000)\n",
      "Value(data=1.000, grad=0.000)\n",
      "Value(data=1.000, grad=1.000)\n",
      "Value(data=2.718, grad=0.368)\n"
     ]
    }
   ],
   "source": [
    "x = Value(2.718)\n",
    "print(x)\n",
    "y = x.log()\n",
    "print(y)\n",
    "y.grad = 1.0\n",
    "y._backward()\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(vec):\n",
    "    '''\n",
    "    takes the natural log of all elements in the vector\n",
    "    '''\n",
    "    assert isinstance(vec, list), \"vec should be a list of Value objects\"\n",
    "    assert all(isinstance(x, Value) for x in vec), \"All elements in vec must be Value objects\"\n",
    "    return [x.log() for x in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(data=-0.330, grad=0.000), Value(data=-0.055, grad=0.000), Value(data=0.393, grad=0.000), Value(data=-0.823, grad=0.000), Value(data=0.685, grad=0.000), Value(data=0.408, grad=0.000), Value(data=0.684, grad=0.000), Value(data=0.064, grad=0.000)]\n",
      "[Value(data=-2.645, grad=0.000), Value(data=-2.369, grad=0.000), Value(data=-1.921, grad=0.000), Value(data=-3.138, grad=0.000), Value(data=-1.630, grad=0.000), Value(data=-1.906, grad=0.000), Value(data=-1.631, grad=0.000), Value(data=-2.251, grad=0.000)]\n",
      "[\n",
      "  [\n",
      "    [Value(data=0.944, grad=0.000), Value(data=0.555, grad=0.000), Value(data=0.215, grad=0.000), Value(data=0.810, grad=0.000), Value(data=-0.920, grad=0.000), Value(data=-0.456, grad=0.000), Value(data=0.556, grad=0.000), Value(data=0.064, grad=0.000)]\n",
      "    [Value(data=-0.479, grad=0.000), Value(data=-0.745, grad=0.000), Value(data=0.126, grad=0.000), Value(data=0.850, grad=0.000), Value(data=0.338, grad=0.000), Value(data=-0.197, grad=0.000), Value(data=-0.261, grad=0.000), Value(data=-0.951, grad=0.000)]\n",
      "    [Value(data=0.765, grad=0.000), Value(data=0.013, grad=0.000), Value(data=0.492, grad=0.000), Value(data=-0.172, grad=0.000), Value(data=-0.312, grad=0.000), Value(data=0.045, grad=0.000), Value(data=-0.591, grad=0.000), Value(data=0.123, grad=0.000)]\n",
      "  ]\n",
      "  [\n",
      "    [Value(data=0.897, grad=0.000), Value(data=-0.098, grad=0.000), Value(data=-0.631, grad=0.000), Value(data=-0.081, grad=0.000), Value(data=-0.760, grad=0.000), Value(data=0.905, grad=0.000), Value(data=-0.892, grad=0.000), Value(data=-0.350, grad=0.000)]\n",
      "    [Value(data=-0.910, grad=0.000), Value(data=0.539, grad=0.000), Value(data=0.028, grad=0.000), Value(data=0.739, grad=0.000), Value(data=-0.589, grad=0.000), Value(data=0.198, grad=0.000), Value(data=-0.120, grad=0.000), Value(data=0.115, grad=0.000)]\n",
      "    [Value(data=0.105, grad=0.000), Value(data=0.406, grad=0.000), Value(data=0.298, grad=0.000), Value(data=0.710, grad=0.000), Value(data=0.377, grad=0.000), Value(data=-0.326, grad=0.000), Value(data=-0.751, grad=0.000), Value(data=0.079, grad=0.000)]\n",
      "  ]\n",
      "]\n",
      "[\n",
      "  [\n",
      "    [Value(data=-1.511, grad=0.000), Value(data=-1.900, grad=0.000), Value(data=-2.239, grad=0.000), Value(data=-1.644, grad=0.000), Value(data=-3.375, grad=0.000), Value(data=-2.911, grad=0.000), Value(data=-1.899, grad=0.000), Value(data=-2.391, grad=0.000)]\n",
      "    [Value(data=-2.552, grad=0.000), Value(data=-2.818, grad=0.000), Value(data=-1.947, grad=0.000), Value(data=-1.223, grad=0.000), Value(data=-1.735, grad=0.000), Value(data=-2.270, grad=0.000), Value(data=-2.334, grad=0.000), Value(data=-3.023, grad=0.000)]\n",
      "    [Value(data=-1.443, grad=0.000), Value(data=-2.195, grad=0.000), Value(data=-1.717, grad=0.000), Value(data=-2.381, grad=0.000), Value(data=-2.520, grad=0.000), Value(data=-2.164, grad=0.000), Value(data=-2.800, grad=0.000), Value(data=-2.085, grad=0.000)]\n",
      "  ]\n",
      "  [\n",
      "    [Value(data=-1.285, grad=0.000), Value(data=-2.280, grad=0.000), Value(data=-2.813, grad=0.000), Value(data=-2.263, grad=0.000), Value(data=-2.942, grad=0.000), Value(data=-1.277, grad=0.000), Value(data=-3.074, grad=0.000), Value(data=-2.532, grad=0.000)]\n",
      "    [Value(data=-3.110, grad=0.000), Value(data=-1.661, grad=0.000), Value(data=-2.172, grad=0.000), Value(data=-1.460, grad=0.000), Value(data=-2.788, grad=0.000), Value(data=-2.002, grad=0.000), Value(data=-2.319, grad=0.000), Value(data=-2.085, grad=0.000)]\n",
      "    [Value(data=-2.170, grad=0.000), Value(data=-1.869, grad=0.000), Value(data=-1.977, grad=0.000), Value(data=-1.564, grad=0.000), Value(data=-1.898, grad=0.000), Value(data=-2.601, grad=0.000), Value(data=-3.026, grad=0.000), Value(data=-2.196, grad=0.000)]\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "x = [Value(r.uniform(-1,1)) for _ in range(model_dim)]\n",
    "print(x)\n",
    "y = log(softmax(x))\n",
    "print(y)\n",
    "\n",
    "x = [[[Value(r.uniform(-1,1)) for _ in range(model_dim)]\n",
    "      for _ in range(seq_len)]\n",
    "     for _ in range(batch_size)]\n",
    "pretty_print_tensor(x)\n",
    "y = vector_wise_apply(log, vector_wise_apply(softmax, x))\n",
    "pretty_print_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make Embedding module also do unembedding w/ shared weights? \n",
    "# wouldn't be exactly faithful to pytorch implementation but i'd like to use gradient accumulation & save parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 8]\n",
      "[2, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "x = [[[Value(r.uniform(-1,1)) for _ in range(model_dim)]\n",
    "      for _ in range(seq_len)]\n",
    "     for _ in range(batch_size)]\n",
    "print(get_shape(x))\n",
    "layer = ResidualLayer(model_dim, num_heads, head_dim, max_seq_len, mlp_mult)\n",
    "y = layer(x)\n",
    "print(get_shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
